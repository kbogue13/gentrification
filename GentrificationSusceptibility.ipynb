{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Script written by K.Bogue as part of his 2018 Master of Science in Geospatial Technoogies degree at the University of Washington\n",
    "'''\n",
    "It is expected that you have read the README accompanying this script before running it.\n",
    "\n",
    "For this script to run you must have the Google Chrome web browser as well as the python libraries for\n",
    "selenium, pandas and geopandas installed.\n",
    "\n",
    "Additionally, you will need a Chrome webdriver. One has been provided for you in the GitHub repository or your own can be found\n",
    "at https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "\n",
    "You will be asked to provide a path to your 'Downloads' folder and a path to the Chrome webdriver.\n",
    "\n",
    "By default the Chrome browser downloads to your computer's downloads folder. If you have altered Chrome's download destination,\n",
    "this script may fail.\n",
    "\n",
    "If running this script multiple times, best practice is to empty the 'Downloads' folder before running again\n",
    "\n",
    "Running this script behind a VPN can cause it to fail. It is recommended you desconnect from your VPN before proceeding.\n",
    "\n",
    "This script was written in Python 3.6\n",
    "'''\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import functools\n",
    "import time\n",
    "\n",
    "#User set downloads folder\n",
    "while True:\n",
    "    dPath = input(r\"Please enter the path to your 'Downloads' folder: \")\n",
    "    try:\n",
    "        if os.path.exists(dPath) == True:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    if os.path.exists(dPath)==False:\n",
    "        print ('The provided folder does not exist')\n",
    "        print (r'The path should be similar to C:\\Users\\YOURNAME\\Downloads')\n",
    "        print ('Please try again')\n",
    "        continue\n",
    "    if dPath.endswith('Downloads') == True:\n",
    "        break\n",
    "    if dPath.endswith('Downloads') == False:\n",
    "        dPath = dPath + \"\\Downloads\"\n",
    "        pass\n",
    "        if os.path.exists(dPath) == True:\n",
    "            break\n",
    "        else:\n",
    "            print('Invalid path')\n",
    "            print (r'The path should be similar to C:\\Users\\YOURNAME\\Downloads')\n",
    "            print('Please try again')\n",
    "            continue\n",
    "\n",
    "downloadPath = dPath\n",
    "\n",
    "#User provide path to Chrome driver\n",
    "while True:\n",
    "    try:\n",
    "        cPath = input(r'Please enter the path to the Google Chrome web driver: ')\n",
    "        if os.path.exists(cPath) == True:\n",
    "            pass\n",
    "        if cPath.endswith('chromedriver.exe') == True:\n",
    "            print('Please wait...')\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "    if (os.path.exists(cPath))==False:\n",
    "        print ('The provided path is invalid')\n",
    "        print ('Please try again')\n",
    "        continue\n",
    "    if (cPath.endswith('chromedriver.exe')) == False:\n",
    "        cPath = cPath + '\\chromedriver.exe'\n",
    "        pass\n",
    "        if os.path.exists(cPath) == True:\n",
    "            print ('Please wait...')\n",
    "            break\n",
    "        else:\n",
    "            print ('The provided path is invalid')\n",
    "            print ('Please try again')\n",
    "            continue\n",
    "\n",
    "chromePath = cPath\n",
    "\n",
    "driver = webdriver.Chrome(chromePath)\n",
    "\n",
    "#functions making selenium wait for specific circumstances\n",
    "\n",
    "def smallWait(): #This is just a general wait of .33 seconds\n",
    "    timeout = .33 #second\n",
    "    try:\n",
    "        element_present = EC.presence_of_element_located((By.XPATH, '//*[@id=\"filterDimensionListId'))\n",
    "        WebDriverWait(driver, timeout).until(element_present)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def medWait(): #This is just a general wait of 1 second\n",
    "    timeout = 1 #second\n",
    "    try:\n",
    "        element_present = EC.presence_of_element_located((By.XPATH, '//*[@id=\"filterDimensionListId'))\n",
    "        WebDriverWait(driver, timeout).until(element_present)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def wait(): #Waits for the loading screen to disappear before proceeding\n",
    "    timeout =  100 #seconds\n",
    "    element_present = EC.presence_of_element_located((By.XPATH, '//*[@id=\"dummy\"]'))\n",
    "    smallWait()\n",
    "    if element_present == True:\n",
    "        WebDriverWait(driver, timeout).until(element_present == False)\n",
    "        smallWait()\n",
    "\n",
    "def downloadWait(): #continually checks for 'download' button to be clickable\n",
    "    timeout = .01 #seconds\n",
    "    while True:\n",
    "        try:\n",
    "            element_present = EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"yui-gen2-button\"]'''))\n",
    "            WebDriverWait(driver, timeout).until(element_present)\n",
    "            break\n",
    "        except TimeoutException:\n",
    "            pass\n",
    "        if element_present == False:\n",
    "            WebDriverWait(driver, timeout).until(element_present)\n",
    "\n",
    "#time how long the code takes\n",
    "start = time.time()\n",
    "\n",
    "'''Make driver navigate to American Fact Finder Download Center and download data'''\n",
    "\n",
    "driver.get('https://factfinder.census.gov/faces/nav/jsf/pages/download_center.xhtml')\n",
    "#Make driver click 'Next' to go to Dataset\n",
    "smallWait()\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"nextButton\"]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"nextButton\"]''').click() #needs to be triple quoted\n",
    "\n",
    "#Choose Ameriacn Community Survey from drop down\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"filterDimensionListId\"]/option[2]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"filterDimensionListId\"]/option[2]''').click()\n",
    "wait()\n",
    "#choose ACS 5-year from drop down\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"listDimensionListId\"]/option[1]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"listDimensionListId\"]/option[1]''').click()\n",
    "wait()\n",
    "#click 'Add to selection'\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"button_container\"]/a''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"button_container\"]/a''').click()\n",
    "wait()\n",
    "#medWait()\n",
    "\n",
    "#click 'Next' to move to 'Geographies' page\n",
    "driver.find_element_by_xpath('''//*[@id=\"nextButton\"]''').click()\n",
    "wait()\n",
    "#select 'Block Group' as the geographic type\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"summaryLevel\"]/option[15]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"summaryLevel\"]/option[15]''').click()\n",
    "\n",
    "#User select state\n",
    "\n",
    "state = str()\n",
    "while True:\n",
    "    try: \n",
    "        state = str(input(\"What STATE contains your area of interest?  \").title())\n",
    "        selectState = Select(driver.find_element_by_id(\"state\"))\n",
    "        for option in selectState.options:\n",
    "            if option.text == state:\n",
    "                selectState.select_by_visible_text(state)\n",
    "                break\n",
    "    except:\n",
    "        if state != str():\n",
    "            print (\"Invalid input\")\n",
    "\n",
    "    if option.text != state:\n",
    "        print (\"State not recognized. Please try again\")\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.ID, '''county''')))\n",
    "\n",
    "#User select county\n",
    "county = str()\n",
    "while True:\n",
    "    try:\n",
    "        county = str(input(\"What COUNTY contains your area of interest?  \").title())\n",
    "        selectCounty = Select(driver.find_element_by_id(\"county\"))\n",
    "        for option in selectCounty.options:\n",
    "            if option.text == county:\n",
    "                selectCounty.select_by_visible_text(county)\n",
    "                break\n",
    "    except:\n",
    "        if county != str():\n",
    "            print (\"Invalid input\")\n",
    "\n",
    "    if county.endswith('County') == True:\n",
    "        county = county[:-7]\n",
    "        pass\n",
    "        for option in selectCounty.options:\n",
    "            if option.text == county:\n",
    "                selectCounty.select_by_visible_text(county)\n",
    "                break\n",
    "        else:\n",
    "            print (\"County not recognized. Please try again\")\n",
    "            continue\n",
    "    if option.text != county:\n",
    "        print (\"County not recognized. Please try again\")\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print('Acquiring tabular demographic data...')\n",
    "medWait()\n",
    "wait()\n",
    "\n",
    "#click on All Block Groups for X\n",
    "driver.find_element_by_xpath('''//*[@id=\"geoAssistList\"]/option''').click()\n",
    "smallWait()\n",
    "wait()\n",
    "\n",
    "#click 'ADD TO YOUR SELECTIONS' button\n",
    "driver.find_element_by_xpath('''//*[@id=\"addtoyourselections\"]''').click()\n",
    "smallWait()\n",
    "wait()\n",
    "medWait()\n",
    "wait()\n",
    "smallWait()\n",
    "#click 'NEXT' to move to SEARCH RESULTS page\n",
    "WebDriverWait(driver, 500).until(EC.presence_of_element_located((By.XPATH, '''//*[@id=\"nextButton\"]''')))\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"nextButton\"]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"nextButton\"]''').click()\n",
    "\n",
    "#Enter B19013, B02001, B25071, B25077, B15003  into search bar this is Median Income, Race, Rent as % of Household Income, Median Home Value, and Educational Attainment\n",
    "#smallWait()\n",
    "wait()\n",
    "smallWait()\n",
    "medWait()\n",
    "WebDriverWait(driver, 500).until(EC.presence_of_element_located((By.XPATH, '''//*[@id=\"prodautocomplete\"]''')))\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"prodautocomplete\"]''')))\n",
    "inputElement = driver.find_element_by_xpath('''//*[@id=\"prodautocomplete\"]''')\n",
    "inputElement.click()\n",
    "inputElement.clear()\n",
    "inputElement.send_keys('B19013, B02001, B25071, B25077, B15003')\n",
    "inputElement.send_keys(Keys.ENTER)\n",
    "\n",
    "#Click 'Check All' button\n",
    "#smallWait()\n",
    "wait()\n",
    "medWait()\n",
    "WebDriverWait(driver, 500).until(EC.presence_of_element_located((By.XPATH, '''//*[@id=\"check_all_btn_below\"]''')))\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"check_all_btn_below\"]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"check_all_btn_below\"]''').click()\n",
    "\n",
    "#Click 'Next'\n",
    "medWait()\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"nextButton\"]/img''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"nextButton\"]/img''').click()\n",
    "\n",
    "#download all selected tables\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"dnld_conf_chk\"]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"dnld_conf_chk\"]''').click()\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"yui-gen0-button\"]''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"yui-gen0-button\"]''').click()\n",
    "downloadWait()\n",
    "\n",
    "#Click 'Download' once it appears\n",
    "driver.find_element_by_xpath('''//*[@id=\"yui-gen2-button\"]''').click()\n",
    "print('Downloading tabular demographic data')\n",
    "\n",
    "'''Download TIGER shapefiles'''\n",
    "\n",
    "print('Acquiring geographic data...')\n",
    "driver.get('https://www.census.gov/cgi-bin/geo/shapefiles/index.php')\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"year\"]/option[2]''')))\n",
    "\n",
    "#Choose year 2016 to match ACS\n",
    "driver.find_element_by_xpath('''//*[@id=\"year\"]/option[2]''').click()\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"layergroup\"]/option[3]''')))\n",
    "#Choose block groups\n",
    "driver.find_element_by_xpath('''//*[@id=\"layergroup\"]/option[3]''').click()\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"left-column\"]/div/form/table/tbody/tr[3]/td[2]/input''')))\n",
    "#Click 'Submit'\n",
    "driver.find_element_by_xpath('''//*[@id=\"left-column\"]/div/form/table/tbody/tr[3]/td[2]/input''').click()\n",
    "#Choose State\n",
    "while True:\n",
    "    try: \n",
    "        selectState = Select(driver.find_element_by_id(\"fips_34\"))\n",
    "        for option in selectState.options:\n",
    "            if option.text == state:\n",
    "                selectState.select_by_visible_text(state)\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if option.text != state:\n",
    "        print (\"State not recognized. Please try again\")\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "#Click 'Download'\n",
    "WebDriverWait(driver, 500).until(EC.element_to_be_clickable((By.XPATH, '''//*[@id=\"middle-column\"]/div/ul/li/input''')))\n",
    "driver.find_element_by_xpath('''//*[@id=\"middle-column\"]/div/ul/li/input''').click()\n",
    "\n",
    "print('Downloading geographic data')\n",
    "\n",
    "#unzip American Fact Finder zip when it finishes downloading\n",
    "while True:\n",
    "    try:\n",
    "        dx = [f for f in listdir(downloadPath) if isfile(join(downloadPath, f))]\n",
    "        for x in dx:\n",
    "            if x.endswith(\"aff_download.zip\"):\n",
    "                file = downloadPath + \"\\\\\" + x\n",
    "                zip_Tiger = zipfile.ZipFile(file , 'r')\n",
    "                zip_Tiger.extractall(downloadPath)\n",
    "                zip_Tiger.close()\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    if x.endswith(\"aff_download.zip\")==False:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "#unzip TIGER shapefile when it finishes downloading\n",
    "while True:\n",
    "    try:\n",
    "        dl = [f for f in listdir(downloadPath) if isfile(join(downloadPath, f))]\n",
    "        for x in dl:\n",
    "            if x.endswith(\"bg.zip\"):\n",
    "                file = downloadPath + \"\\\\\" + x\n",
    "                zip_Tiger = zipfile.ZipFile(file , 'r')\n",
    "                zip_Tiger.extractall(downloadPath)\n",
    "                zip_Tiger.close()\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    if x.endswith(\"bg.zip\")==False:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "print('Calculating...')\n",
    "\n",
    "#Close Chrome\n",
    "driver.quit()\n",
    "\n",
    "#Turn off warnings for calculating only slices of data\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#Identify CSVs\n",
    "fname = downloadPath + '\\ACS_16_5YR_B02001_with_ann.csv' #Race\n",
    "fname1 = downloadPath + '\\ACS_16_5YR_B19013_with_ann.csv' #Median Income\n",
    "fname2 = downloadPath + '\\ACS_16_5YR_B25071_with_ann.csv' #Rent as % of MI\n",
    "fname3 = downloadPath + '\\ACS_16_5YR_B25077_with_ann.csv' #Housing Value\n",
    "fname4 = downloadPath + '\\ACS_16_5YR_B15003_with_ann.csv' #Educational Attainment\n",
    "\n",
    "#RACE\n",
    "outF = downloadPath + '\\Race.csv'\n",
    "with open(fname, 'r') as inFile, open(outF, 'w') as outFile:\n",
    "    r = csv.reader(inFile)\n",
    "    w = csv.writer(outFile)\n",
    "    \n",
    "    #read the header\n",
    "    header = next(r)\n",
    "    \n",
    "    #change header titles\n",
    "    header[1] = 'GEOID'\n",
    "    header[3] = 'TotalPop'\n",
    "    header[5] = 'WhitePpl'\n",
    "    header[6] = 'PctWhite'\n",
    "    header[7] = 'Score'\n",
    "    w.writerow(header)\n",
    "    \n",
    "    #copy the rest of the data\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "\n",
    "#Calculate percentage of white people\n",
    "df1=pd.read_csv(outF, usecols = ['GEOID', 'TotalPop', 'PctWhite', 'WhitePpl', 'Score'], converters={'GEOID': lambda x: str(x)})\n",
    "df1['PctWhite'] = df1['WhitePpl'] / df1['TotalPop']\n",
    "\n",
    "#Calculate quantiles\n",
    "below20 = df1.PctWhite.quantile((.2), 'lower')\n",
    "below40 = df1.PctWhite.quantile((.4), 'lower')\n",
    "below60 = df1.PctWhite.quantile((.6), 'lower')\n",
    "below80 = df1.PctWhite.quantile((.8), 'lower')\n",
    "\n",
    "#write quantiles to CSV\n",
    "pctWhite = df1['PctWhite']\n",
    "\n",
    "df1.Score.loc[pctWhite <= below20] = 5\n",
    "df1.Score.loc[pctWhite > below20] = 4\n",
    "df1.Score.loc[pctWhite > below40] = 3\n",
    "df1.Score.loc[pctWhite > below60] = 2\n",
    "df1.Score.loc[pctWhite > below80] = 1  \n",
    "df1.Score.loc[df1.Score > 5] = 0 #gives a zero to block groups whose scores aren't compatible\n",
    "\n",
    "df1.to_csv(outF)\n",
    "\n",
    "#MEDIAN INCOME\n",
    "outF1 = downloadPath + '\\MedianIncome.csv'\n",
    "with open(fname1, 'r') as inFile, open(outF1, 'w') as outFile:\n",
    "    r = csv.reader(inFile)\n",
    "    w = csv.writer(outFile)\n",
    "    \n",
    "    #read the header\n",
    "    header = next(r)\n",
    "    \n",
    "    #change header titles\n",
    "    header[1] = 'GEOID'\n",
    "    header[3] = 'MI'\n",
    "    header[4] = 'MI_Score'\n",
    "    \n",
    "    w.writerow(header)\n",
    "    #copy the rest of the data\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "        \n",
    "#Remove characters that casue MI to be read as a string\n",
    "df99 = pd.read_csv(outF1, usecols = ['GEOID', 'MI', 'MI_Score'], converters={'GEOID': lambda x: str(x)})\n",
    "MI = df99['MI']\n",
    "for i in MI:\n",
    "    if i == '-':\n",
    "        df99.MI.loc[MI == ('-')] = 0\n",
    "    if i == '2,500-':\n",
    "        df99.MI.loc[MI == '2,500-'] = 2500\n",
    "    if i == '5,000-':\n",
    "        df99.MI.loc[MI == '5,000-'] = 5000\n",
    "    if i == '250,000+':\n",
    "        df99.MI.loc[MI == '250,000+'] = 250000\n",
    "\n",
    "df99.to_csv(outF1)\n",
    "\n",
    "#Calculate quantiles for median income\n",
    "df2 = pd.read_csv(outF1, usecols = ['GEOID', 'MI', 'MI_Score'], converters=({'GEOID': lambda x: str(x), 'MI': lambda y: int(y)}))\n",
    "\n",
    "MIbelow20 = df2.MI.quantile((.2), 'lower')\n",
    "MIbelow40 = df2.MI.quantile((.4), 'lower')\n",
    "MIbelow60 = df2.MI.quantile((.6), 'lower')\n",
    "MIbelow80 = df2.MI.quantile((.8), 'lower')\n",
    "\n",
    "medIncome = df2['MI']\n",
    "\n",
    "df2.MI_Score.loc[medIncome <= MIbelow20] = 5\n",
    "df2.MI_Score.loc[medIncome > MIbelow20] = 4\n",
    "df2.MI_Score.loc[medIncome > MIbelow40] = 3\n",
    "df2.MI_Score.loc[medIncome > MIbelow60] = 2\n",
    "df2.MI_Score.loc[medIncome > MIbelow80] = 1\n",
    "df2.MI_Score.loc[medIncome == 0] = 0 \n",
    "\n",
    "\n",
    "df2.to_csv(outF1)\n",
    "#RENT AS % OF MEDIAN INCOME\n",
    "outF2 = downloadPath + '\\RentPct.csv'\n",
    "with open(fname2, 'r') as inFile, open(outF2, 'w') as outFile:\n",
    "    r = csv.reader(inFile)\n",
    "    w = csv.writer(outFile)\n",
    "    \n",
    "    #read the header\n",
    "    header = next(r)\n",
    "    \n",
    "    #change header titles\n",
    "    header[1] = 'GEOID'\n",
    "    header[3] = 'RentPct'\n",
    "    header[4] = 'Rent_Score'\n",
    "    \n",
    "    w.writerow(header)\n",
    "    #copy the rest of the data\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "\n",
    "df98 = pd.read_csv(outF2, usecols = ['GEOID', 'RentPct', 'Rent_Score'], converters={'GEOID': lambda x: str(x)})\n",
    "RentPct = df98['RentPct']\n",
    "for a in RentPct:\n",
    "    if a == '-':\n",
    "        df98.RentPct.loc[RentPct == ('-')] = 0\n",
    "    if a == '50.0+':\n",
    "        df98.RentPct.loc[RentPct == ('50.0+')] = 50.0\n",
    "    if a == '10.0-':\n",
    "        df98.RentPct.loc[RentPct == ('10.0-')] = 10.0\n",
    "\n",
    "df98.to_csv(outF2) \n",
    "       \n",
    "df3 = pd.read_csv(outF2, usecols = ['GEOID', 'RentPct', 'Rent_Score'], converters=({'GEOID': lambda x: str(x), 'RentPct': lambda y: str(y)}))\n",
    "\n",
    "RENTbelow20 = df3.RentPct.quantile((.2), 'lower')\n",
    "RENTbelow40 = df3.RentPct.quantile((.4), 'lower')\n",
    "RENTbelow60 = df3.RentPct.quantile((.6), 'lower')\n",
    "RENTbelow80 = df3.RentPct.quantile((.8), 'lower')\n",
    "\n",
    "rent = df3['RentPct']\n",
    "\n",
    "df3.Rent_Score.loc[rent <= RENTbelow20] = 1\n",
    "df3.Rent_Score.loc[rent > RENTbelow20] = 2\n",
    "df3.Rent_Score.loc[rent > RENTbelow40] = 3\n",
    "df3.Rent_Score.loc[rent > RENTbelow60] = 4\n",
    "df3.Rent_Score.loc[rent > RENTbelow80] = 5\n",
    "df3.Rent_Score.loc[RentPct == 0] = 0\n",
    "\n",
    "df3.to_csv(outF2)\n",
    "\n",
    "#HOUSING VALUE\n",
    "outF3 = downloadPath + '\\HousingValue.csv'\n",
    "with open(fname3, 'r') as inFile, open(outF3, 'w') as outFile:\n",
    "    r = csv.reader(inFile)\n",
    "    w = csv.writer(outFile)\n",
    "    \n",
    "    #read the header\n",
    "    header = next(r)\n",
    "    \n",
    "    #change header titles\n",
    "    header[1] = 'GEOID'\n",
    "    header[3] = 'HouseVal'\n",
    "    header[4] = 'HV_Score'\n",
    "    \n",
    "    w.writerow(header)\n",
    "    #copy the rest of the data\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "\n",
    "df97 = pd.read_csv(outF3, usecols = ['GEOID', 'HouseVal', 'HV_Score'], converters={'GEOID': lambda x: str(x)})\n",
    "HouseVal = df97['HouseVal']\n",
    "\n",
    "for h in HouseVal:\n",
    "    if h == '-':\n",
    "        df97.HouseVal.loc[HouseVal == ('-')] = 0\n",
    "    if h == '10,000-':\n",
    "        df97.HouseVal.loc[HouseVal == ('10,000-')] = 10000\n",
    "    if h == '2,000,000+':\n",
    "        df97.HouseVal.loc[HouseVal == ('2,000,000+')] = 2000000\n",
    "\n",
    "df97.to_csv(outF3)\n",
    "       \n",
    "df4 = pd.read_csv(outF3, usecols = ['GEOID', 'HouseVal', 'HV_Score'], converters={'GEOID': lambda x: str(x)})\n",
    "\n",
    "HVbelow20 = df4.HouseVal.quantile((.2), 'lower')\n",
    "HVbelow40 = df4.HouseVal.quantile((.4), 'lower')\n",
    "HVbelow60 = df4.HouseVal.quantile((.6), 'lower')\n",
    "HVbelow80 = df4.HouseVal.quantile((.8), 'lower')\n",
    "\n",
    "HV = df4['HouseVal']\n",
    "HV_S = df4['HV_Score']\n",
    "df4.HV_Score.loc[HV <= HVbelow20] = 5\n",
    "df4.HV_Score.loc[HV > HVbelow20] = 4\n",
    "df4.HV_Score.loc[HV > HVbelow40] = 3\n",
    "df4.HV_Score.loc[HV > HVbelow60] = 2\n",
    "df4.HV_Score.loc[HV > HVbelow80] = 1\n",
    "df4.HV_Score.loc[HV == 0] = 0\n",
    "\n",
    "df4.to_csv(outF3)\n",
    "\n",
    "#EDUCATIONAL ATTAINMENT (Degree >= Bachelor's)\n",
    "outF5 = downloadPath + '\\Education.csv'\n",
    "with open(fname4, 'r') as inFile, open(outF5, 'w') as outFile:\n",
    "    r = csv.reader(inFile)\n",
    "    w = csv.writer(outFile)\n",
    "    \n",
    "    #read the header\n",
    "    header = next(r)\n",
    "    header[1] = 'GEOID'\n",
    "    \n",
    "    w.writerow(header)\n",
    "    #copy the rest of the data\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "\n",
    "df5 = pd.read_csv(outF5, usecols = ['GEOID', 'HD01_VD22', 'HD01_VD23', 'HD01_VD24', 'HD01_VD25'], converters={'GEOID': lambda x: str(x)})\n",
    "df5['CollegeDegree'] = df5['HD01_VD22'] + df5['HD01_VD23'] + df5['HD01_VD24'] + df5 ['HD01_VD25']\n",
    "\n",
    "df5.to_csv(outF5)\n",
    "\n",
    "df6 = pd.read_csv(outF5, usecols = ['GEOID', 'CollegeDegree'], converters={'GEOID': lambda x: str(x)})\n",
    "\n",
    "df6.to_csv(outF5)\n",
    "\n",
    "#Combine all csv's into one\n",
    "outF4 = downloadPath + '\\FINAL.csv'\n",
    "\n",
    "dfs = [df1, df2, df3, df4, df6]\n",
    "\n",
    "df_final = functools.reduce(lambda left,right: pd.merge(left,right,on='GEOID'), dfs)\n",
    "\n",
    "#Calculate % of people with a Bachelor's Degree or higher\n",
    "df_final['DegreePct'] = df6['CollegeDegree'] / df1['TotalPop']\n",
    "\n",
    "DGbelow20 = df_final.DegreePct.quantile((.2), 'lower')\n",
    "DGbelow40 = df_final.DegreePct.quantile((.4), 'lower')\n",
    "DGbelow60 = df_final.DegreePct.quantile((.6), 'lower')\n",
    "DGbelow80 = df_final.DegreePct.quantile((.8), 'lower')\n",
    "\n",
    "df_final['Degree_Score'] = 0\n",
    "DG = df_final['DegreePct']\n",
    "\n",
    "df_final.Degree_Score.loc[DG <= DGbelow20] = 5\n",
    "df_final.Degree_Score.loc[DG > DGbelow20] = 4\n",
    "df_final.Degree_Score.loc[DG > DGbelow40] = 3\n",
    "df_final.Degree_Score.loc[DG > DGbelow60] = 2\n",
    "df_final.Degree_Score.loc[DG > DGbelow80] = 1\n",
    "\n",
    "#Total all scores\n",
    "df_final['TotalScore'] = df1['Score'] + df2['MI_Score'] + df3['Rent_Score'] + df4['HV_Score'] + df_final['Degree_Score']\n",
    "\n",
    "#calculate number of scores for which there is data\n",
    "df_final['Num_of_Values'] = 0\n",
    "\n",
    "df_final.to_csv(outF4)\n",
    "\n",
    "#Divide total score by number of actual score entries\n",
    "df7 = pd.read_csv(outF4, converters={'GEOID': lambda x: str(x)})\n",
    "\n",
    "div = df7['Num_of_Values']\n",
    "Score = df1['Score']\n",
    "Score2 = df2['MI_Score']\n",
    "Score3 = df3['Rent_Score']\n",
    "Score4 = df4['HV_Score']\n",
    "Score5 = df_final['Degree_Score']\n",
    "\n",
    "df7.Num_of_Values.loc[Score > 0] = div + 1\n",
    "df7.Num_of_Values.loc[Score2 > 0] = div + 1\n",
    "df7.Num_of_Values.loc[Score3 > 0] = div + 1\n",
    "df7.Num_of_Values.loc[Score4 > 0] = div + 1\n",
    "df7.Num_of_Values.loc[Score5 > 0] = div + 1\n",
    "\n",
    "df7['AvgScore'] = (df7['TotalScore'] / df7['Num_of_Values'])\n",
    "\n",
    "df7.to_csv(outF4)\n",
    "\n",
    "df8 = pd.read_csv(outF4, usecols = ['GEOID', 'TotalPop', 'PctWhite', 'Score', 'MI', 'MI_Score', 'RentPct', 'Rent_Score', 'HouseVal', 'HV_Score', 'CollegeDegree', 'DegreePct', 'Degree_Score', 'TotalScore', 'AvgScore' ],converters={'GEOID': lambda x: str(x)})\n",
    "df8.to_csv(outF4)\n",
    "#read Block Groups shapefile\n",
    "ifiles = [f for f in listdir(downloadPath) if isfile(join(downloadPath, f))]\n",
    "for i in ifiles:\n",
    "    if i.endswith(\".shp\"):\n",
    "        ifile = downloadPath + \"\\\\\" + i\n",
    "\n",
    "blockGroups = gpd.GeoDataFrame.from_file(ifile)\n",
    "\n",
    "#converters={'GEOID': lambda x: str(x)} This stops Pandas from deleting leading 0 in census numbers\n",
    "final = pd.read_csv(outF4, converters={'GEOID': lambda x: str(x)})\n",
    "\n",
    "#Merge tabular data with geometry in that order\n",
    "finalBG = pd.merge(final, blockGroups, on='GEOID')\n",
    "\n",
    "#Save to new shapefile\n",
    "outF5 = downloadPath + '\\GentrificationSusceptibility.shp'\n",
    "\n",
    "shapefile = gpd.GeoDataFrame(finalBG, geometry='geometry')\n",
    "\n",
    "# proj WGS84\n",
    "shapefile.crs= \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "\n",
    "shapefile.to_file(outF5, driver='ESRI Shapefile')\n",
    "\n",
    "elapsed = (time.time() - start)\n",
    "\n",
    "print('FINISHED!') \n",
    "print('A shapefile named \"GentrificationSusceptibility.shp\" can be found in your Downloads folder. It can be viewed using your preferred visualization or GIS software.')\n",
    "print('The process took '+ str(int(elapsed)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
